{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f52005",
   "metadata": {},
   "source": [
    "# 관세 데이터\n",
    "\n",
    "출처: UNCTAD (2012), *A Practical Guide to Trade Policy Analysis*, [Chapter 2](https://unctad.org/system/files/official-document/gds2012d2_ch2_en.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04941b99",
   "metadata": {},
   "source": [
    "- [1. 집중성 마진과 확장성 마진](#1.-집중성-마진과-확장성-마진)\n",
    "- [2. 간단한 숫자 예](#2.-간단한-숫자-예)\n",
    "- [3. 2022년 상품 수출 데이터](#3.-2022년-상품-수출-데이터)\n",
    "- [4. 주요국 집중성 마진과 확장성 마진](#4.-주요국-집중성-마진과-확장성-마진)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf130b",
   "metadata": {},
   "source": [
    "### A. 개요 및 학습 목표\n",
    "\n",
    "이 장에서는 무역 정책 정량화에 사용되는 주요 기법을 소개합니다. 구체적으로, 무역 정책을 설명하고, 요약하며, 정량화하는 데 사용되는 도구들을 다룹니다. 원래 관세 데이터는 집계가 필요하고 특정 관세를 종가세로 환산해야 하므로 다루기 번거로울 수 있습니다. 관세 구조를 설명할 때 흔히 발생하는 세 가지 문제, 즉 유효 보호율의 계산, 관련된 관세 승수 현상, 그리고 수입 가중 평균치를 사용할 때 고관세가 과소평가되는 문제에 대해 논의합니다. 비관세조치(NTM)와 관련해서는 그 다양성과 엄격성을 평가하는 어려움 때문에 측정이 더 복잡합니다.\n",
    "\n",
    "먼저, 다양한 무역 정책의 특징을 설명하는 데 사용되는 여러 접근법을 소개합니다. 단순한 관세 프로필로 시작하여 다양한 관세 지표를 계산하는 방법을 간략히 설명합니다. 이후, 비관세조치(NTM)에 주목하며, 수입 커버리지 비율과 가격 차이 방법을 사용하여 NTM의 발생 빈도와 무역에 미치는 영향을 어떻게 추정할 수 있는지 알아봅니다. 이어서, 전반적인 무역 제한 지수를 정의하고 계산하려는 최근 시도를 살펴봅니다. 분석 도구에 대한 논의를 마친 후, 주요 관세 및 비관세조치 데이터 소스를 소개합니다. 마지막으로, 이 장의 세 번째 부분에서는 첫 번째 부분에서 소개된 지표를 두 번째 부분에서 제공된 데이터 소스를 활용해 STATA 소프트웨어를 사용하여 계산하는 방법을 보여줍니다.\n",
    "\n",
    "이 장에서는 무역 조치의 효과에 대해서는 다루지 않습니다. 관세, 쿼터, 보조금이 완전 경쟁 또는 불완전 경쟁 하에서 무역과 복지에 미치는 영향을 다루는 부분 균형 또는 일반 균형 분석은 대부분의 학부 국제 경제학 교과서에서 확인할 수 있습니다.\n",
    "\n",
    "이 장을 통해 다음을 학습할 수 있습니다:\n",
    "- 특정 국가의 관세 구조의 주요 특징을 요약한 관세 프로필을 제시하는 방법\n",
    "- 단순 평균 및 가중 평균으로 관세를 집계하는 방법과 집계 시 발생할 수 있는 편향\n",
    "- 유효보호율(Effective Rates of Protection)을 정의하고 계산하는 방법\n",
    "- 관세 승수(tariff escalation)를 측정하고 해석하는 방법\n",
    "- 비관세조치(NTM) 수입 커버리지 비율을 계산하는 방법과 계산 시 발생할 수 있는 편향\n",
    "- 가격 차이(price-gap) 방법을 사용하여 수량 제한(QR: quantitative restriction)의 종가세 등가값(ad valorem tariff equivalent)을 계산하는 방법\n",
    "- 무역 정책 태도의 전반적인 무역 제한성(overall trade restrictiveness)을 평가하는 방법\n",
    "- 주요 데이터베이스에서 관세 및 비관세조치 데이터가 제공되는 방식\n",
    "\n",
    "이 장을 읽고 나면, 적절한 정보를 활용하여 무역 정책 분석을 수행할 수 있으며, 이를 정보 전달이 용이하면서도 간결하게 제시할 수 있습니다. 이는 1장에서 다룬 무역 흐름 분석과 마찬가지로 전문가와 비전문가 모두가 쉽게 이해할 수 있는 형태로 표현될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a98e7",
   "metadata": {},
   "source": [
    "## B. 분석 도구\n",
    "\n",
    "### B. 분석 도구\n",
    "\n",
    "무역 정책은 정부가 국제 무역과 관련하여 채택하는 정책을 의미하며, 다양한 조치와 여러 도구를 활용할 수 있습니다. 이러한 도구에는 수입 또는 수출에 대한 세금, 국제 거래의 정량적 제한, 보조금, 그리고 관세 및 비관세조치(NTMs)로 크게 나뉘는 다양한 조치들이 포함됩니다. 정부는 수입하거나 수출하는 수천 개의 제품에 대해 이러한 조치를 다양한 조합으로 적용합니다. 예를 들어, 관세라는 동일한 조치라도 제품에 따라 다른 수준으로 설정되며, 이로 인해 무역에 매우 상이한 영향을 미칠 수 있습니다. 이 장에서는 국가의 무역 정책을 요약 통계로 간결하고 효과적으로 표현하여 주요 특징을 포착하고 반영하는 방법을 설명합니다. 이 과정에서 제품 간, 그리고 상이한 조치 간의 집계가 도전 과제가 됩니다.\n",
    "\n",
    "경제학자들은 일반적으로 무역 정책이 다양한 목적을 가질 수 있음을 인식하지만, 주로 정책의 제한성(restrictiveness)에 초점을 맞춥니다. 그렇다면 왜 경제학자들은 특정 국가의 무역 정책이 얼마나 제한적인지에 관심을 가질까요? 교과서적 논리는 무역 개방이 순수 교환과 특화에서 얻는 이익을 가져온다는 점에서 출발합니다(리카도의 포도주와 직물 사례). 그러나 이 논리는 본질적으로 정태적(static)이어서 설득력이 떨어집니다. 무역 개방에서 얻는 정태적 이익은 GDP의 5% 미만 수준에 불과하며, 10년에 걸친 조정 기간에 걸쳐 분산됩니다. 이는 현재 개발도상국에서 관찰되는 성장률과 비교했을 때 미미한 수준입니다. 따라서 논의의 초점은 무역 개혁과 정태적 복지 간의 관계가 아니라, 무역 개혁과 성장 간의 관계에 있습니다. 이와 관련하여 이론은 비교적 명확한 답을 제공하지 않으며, 본질적으로 경험적(empirical)인 문제로 남아 있습니다.\n",
    "\n",
    "그러나 무역 개방성과 경제 성장 간의 강력한 통계적 연관성을 찾으려는 시도는 오랜 시간이 걸렸습니다. 첫 번째 문제는 정책적 입장을 비교 가능하게 반영할 수 있는 개방성 측정을 개발하는 것이었습니다. 이와 관련된 논의는 이후에 다루겠지만, 여기서는 Sachs와 Warner(1995)가 관찰 가능한 조치를 기반으로 최초의 종합 지수를 제안했다는 점을 언급하는 것으로 충분합니다. 대안적 측정 방식(예: Leamer, 1988)은 회귀 분석에 기반을 두었으며, 관찰된 개방성에 대한 외생적 결정 요인을 회귀 분석하여 얻은 잔차를 \"정책적 개방성\"으로 정의했습니다(1장에서 논의한 내용).\n",
    "\n",
    "국가 횡단면(cross-section) 데이터를 사용한 초기 연구(Edwards, 1998 및 관련 참고 문헌 참조)는 개방성과 성장 간의 상관관계를 생성했지만, 이는 불안정하고 설득력이 약했습니다. 예를 들어, Rodriguez와 Rodrik(1999)은 Sachs-Warner 지수의 순수 무역 요소(각주 3에서 설명한 조건 (i)와 (ii))가 지수의 성장과의 전체적 연관성에 거의 기여하지 않았음을 보여주었습니다. 그러나 Wacziarg와 Welsh(2008)의 논문을 포함한 최근 연구들은 패널 데이터 기법(여러 국가를 여러 해 동안 관찰하여 단면과 시계열 데이터를 모두 활용하는 기법)을 통해 무역 개방성과 성장 간의 더 강력한 상관관계를 밝혀냈습니다. 본질적으로 추가적인 정보는 각 국가에서 무역 자유화가 발생한 시점을 신중하게 식별함으로써 얻어집니다. 이를 통해 자유화 전후의 성장률 사이에 큰 차이가 관찰되었습니다. 따라서, 더 많은 무역 개방이 성장에 긍정적이라는 규범적 관점에서 무역 정책을 분석하는 것은 타당하다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1755",
   "metadata": {},
   "source": [
    "## 1. 관세\n",
    "### a. 개념\n",
    "관세는 국경에서 상품의 수입, 드물게는 수출에 부과되는 세금입니다. 관세의 효과는 수입(수출) 상품의 가격을 세계(국내) 시장 가격보다 높이는 것입니다. 관세는 보통 세관 당국에 의해 징수되며 종가세 또는 종량세일 수 있습니다. 종가세(*ad valorem*)는 수입(수출) 상품의 가치(보통 운임보험료 포함 수입 가치)의 일정 비율로 표시되며, 종량세(specific)는 상품 단위당 고정 통화 금액으로 표시됩니다.\n",
    "\n",
    "종가세는 종량세보다 훨씬 더 널리 사용됩니다. 그 이유 중 하나는 집계하고 비교하기가 더 쉬워서 투명성이 높기 때문입니다. 이는 특히 국가들이 관세 약속을 협상할 때 중요합니다. 종량세는 상품이 측정되는 단위에 따라 다르기 때문에 상품 간 비교가 더 어렵습니다. 그러나 이를 비교하는 한 가지 방법은 종가세 등가값(equivalent)을 계산하는 것입니다 (Box 2.1 참조).\n",
    "\n",
    "관세 체제의 특징 중 간과해서는 안 되는 점은 최종 용도에 따른 면제의 가능성입니다(특수 프로젝트, 수출 가공 구역(EPZ: export processing zone)에서 특수 지위를 가진 다국적 기업, 국제 기구 등). 공식적인 면제 외에도, 정부는 종종 현지 조사에 의해서만 알 수 있는 임시 면제를 부여합니다. 면제가 중요할 때, 이를 간과하면 보호율을 과대평가하게 됩니다. 한 가지 가능한 해결책은 신고된 수입 가치에 대한 수집된 관세의 비율로 보호율을 계산하는 것입니다 (이 내용은 6장에서 더 다룹니다). 그러나 면제 상품과 비면제 상품을 평균화하면 비면제 상품에 대한 보호율을 과소평가하게 됩니다.\n",
    "\n",
    "GATT/WTO와 더 구체적으로 관련된 두 가지 추가 구분을 고려해야 합니다. 첫 번째 구분은 최혜국대우(MFN: most-favoured nation) 관세율과 특혜(preferential) 관세율 간의 차이입니다. MFN 관세는 WTO 회원국이 특혜 협정을 체결하지 않은 모든 다른 WTO 회원국의 수입에 대해 부여하기로 약속한 관세입니다. 특혜 관세는 자유무역협정(FTA), 관세동맹 또는 기타 특혜 무역 협정에서 특혜 파트너의 수입에 대해 부여되는 관세로, 다른 관세보다 0에 가까운 경우가 많습니다.\n",
    "\n",
    "두 번째 구분은 약정(bound) 관세와 적용(applied) 관세 간의 차이입니다. 정부가 GATT/WTO에서 관세 인하를 협상할 때, 그들의 약속은 MFN 관세 약정 형태를 취합니다. 약정된 MFN 관세 수준은 국가의 관세 일정에 나열되어 있으며, 이는 정부가 적용 MFN 관세를 설정하기로 약속한 상한을 나타냅니다. 주어진 관세 품목에 대해 약정된 관세는 적용된 MFN 관세보다 높거나 같아야 하며, 특혜 관세가 있는 경우 특혜 관세보다 높거나 같아야 합니다.\n",
    "\n",
    "선진국의 경우, 약정된 관세는 보통 적용된 관세와 동일하거나 매우 가깝습니다. 그러나 개발도상국의 경우, 종종 \"관세의 물\"이 있어 약정된 관세가 적용된 관세보다 높아 무역 흐름에 제한적인 영향을 미치지만, WTO 협상에서 기본적입니다. 적용된 분석에서 올바른 수입에 올바른 관세를 적용하는 것이 중요합니다 (예: 특혜 파트너의 수입에 MFN 관세를 적용하지 않음). 그러나 실제로 지역 통합 협정에서 특혜 관세가 어느 정도 적용되는지에 대한 상당한 불확실성이 종종 존재합니다, 특히 남남 협정에서."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78946d2",
   "metadata": {},
   "source": [
    "### b. 실증 도구\n",
    "#### i. 관세 프로필\n",
    "**평균**\n",
    "관세 일정은 일반적으로 HS 8자리 수준의 세분화 또는 더 높은 수준(최대 HS 12)으로 정의되며, 주어진 국가에는 항상 5,000개 이상의 관세 품목이 있고 종종 그보다 훨씬 많습니다. 관세는 단순 평균 또는 가중치를 사용하는 방식으로 집계할 수 있습니다. 단순 평균은 모든 관세 품목의 관세를 더하고 그 관세 품목 수로 나누어 계산하는 것이 간단합니다. 가중 평균의 경우, 다음과 같은 형태를 취합니다:\n",
    "\n",
    "$$\n",
    "τ = \\sum w_k τ_k\n",
    "$$\n",
    "\n",
    "여기서 $k$는 수입 상품을 나타내고 $w_k$는 평균에서 관세 $k$에 주어진 가중치입니다 (그리스 문자 $τ$는 시간 지수와의 혼동을 피하기 위해 $t$ 대신 사용됩니다). 널리 사용되는 접근 방식은 상품을 국가의 전체 수입에서의 비율로 가중하는 것입니다.\n",
    "\n",
    "단순 평균과 수입 가중 평균은 계산하기 상대적으로 쉽다는 장점이 있지만, 이 두 가지 방법에는 단점이 있습니다. 단순 평균은 수입되지 않은 제품과 대량으로 수입되는 제품에 동일한 가중치를 부여합니다. 수입 가중 평균의 경우, 이 편향을 어느 정도 수정하지만 높은 관세를 과소평가하며 금지적 관세에는 0의 가중치를 부여합니다.\n",
    "\n",
    "이 문제에 대한 이론적 해결책은 자유 무역 수입 수준을 가중치로 사용하는 것이지만, 이는 관찰할 수 없습니다. Leamer(1974)는 세계 무역을 사용하는 것을 제안했지만, 이는 각국의 무제한 무역 구조를 적절히 나타내지 못합니다. 또 다른 접근 방식은 소득 수준을 기준으로 참조 국가 그룹을 정의하여 \"국가\"와 \"글로벌\" 가중치 사이의 타협을 이루는 것입니다. Kee 등(2005)은 관세 품목 수준에서 수입 비율과 수입 수요의 탄력성이 증가함에 따라 가중치를 제안합니다. 이는 이러한 상품에 대한 제한이 전체 제한성에 미치는 중요성을 포착합니다. 대안적으로, 단순 평균과 가중 평균을 함께 보고할 수 있습니다. 예를 들어, 표 2.2는 SADC 및 COMESA 국가에서의 수입에 적용된 MFN 관세(적용된, 약정되지 않은) 및 특혜 관세를 보여줍니다. 표 2.2는 제품에 따라 단순 평균 또는 가중 평균이 더 높을 수 있음을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaa5e4",
   "metadata": {},
   "source": [
    "- 관세 양허(Concession of Tariff)란 국가 간 관세 적용에 관한 협상에서 협상 당사국이 특정 품목의 관세를 일정 수준 이상으로 부과하지 않겠다고 약속하는 것을 의미한다. 관세 양허의 결과는 당해 국가의 양허관세표(Tariff Schedule) 형태로 협정문에 부속시키며, 일단 관세 양허된 품목의 세율에 대해서는 상대방의 동의 없이는 변경할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859c314",
   "metadata": {},
   "source": [
    "### WTO TAO 제공 정보\n",
    "\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|:-----|:------|\n",
    "|**적용관세 및 무역 (IDB)**|\n",
    "| 관세품목 관세 | 관세품목(tariff line)별 관세에 대한 상세 정보. |\n",
    "| HS 소호 관세 | HS 소호(Subheading)별 관세 및 수입에 대한 상세 정보. |\n",
    "| 평균 관세율 | 단순 평균 및 무역가중 평균 관세율. |\n",
    "| 관세 및 무역 프로필 | 관세 범위(range)별로 정리된 관세 및 무역 정보. |\n",
    "| 주요 공급국 | 시장 점유율 기준으로 정렬된 주요 공급국으로부터의 수입 내역. |\n",
    "| 주요 제품 | HS 류(Chapter), 호(Heading), 소호(Subheading) 수준에서 무역 중요도에 따른 제품 정보. |\n",
    "| 관세 비교 | 두 개의 관세 체제 비교. |\n",
    "| 양허 상태 | 양허 상태에 따른 관세품목 수 및 해당 수입 규모(가능한 경우). |\n",
    "| 수출 시장 관세 부담 | 수출 시장별 관세 및 무역에 대한 요약 및 상세 정보. |\n",
    "||\n",
    "|**양허관세 및 약속 (CTS)**|\n",
    "| 관세 양허 | 관세품목별 관세 양허에 대한 상세 정보. |\n",
    "| 관세 쿼터 | 내·외 쿼터 관세 및 관세 쿼터가 적용되는 제품의 약속 내용. |\n",
    "| 총 AMS 감축 약속 | 회원국별 총 농업보조금(AMS: Aggregate Measure of Support) 감축 약속. |\n",
    "| 수출 보조금 | 제품 및 세율표별 회원국의 수출 보조금 약속 정보. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1dceb4",
   "metadata": {},
   "source": [
    "### MODULE 1 - THEME 2 - ANALYZING TARIFF PROFILES  - APPLICATION 1\n",
    "\n",
    "\n",
    "* 선택된 국가는 2008년 기준 캐나다입니다.  \n",
    "\n",
    "* 데이터 출처:  \n",
    "  - WTO [TAO](http://tao.wto.org)에서 제공하는 Bound Concessions, Tariff and Trade details(양허 관세, 관세 및 무역 세부사항) \n",
    "  - TAO: WTO's Integrated Data Base (IDB) and Consolidated Tariff Schedules (CTS) database on-line\n",
    "  - 참고: 명령어는 [WITS](https://wits.worldbank.org/)에서 제공되는 데이터에 약간 수정하여 적용할 수 있습니다.  \n",
    "\n",
    "* 사용된 데이터:  \n",
    "  - DutyDetails.txt  \n",
    "  - HS96Complete.dta  \n",
    "  - ProdGrp_hs96at6dig.dta  \n",
    "  - ProdGrp_hs07at6dig.dta  \n",
    "\n",
    "* 저장된 데이터:  \n",
    "  - DutyDetails.dta  \n",
    "  - TradeDetails.dta  \n",
    "  - TariffDetails.dta  \n",
    "  - Bounds.dta  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af86b2",
   "metadata": {},
   "source": [
    "### 데이터베이스 가져오기 \n",
    "\n",
    "* TAO/IDB에서 제공된 파일(txt 형식)을 Stata로 가져옵니다.  \n",
    "* 데이터를 Excel에서 가져온 경우, 각 워크시트를 별도의 워크시트로 저장한 후 .txt 또는 .csv 파일로 저장해야 합니다.  \n",
    "* 양허 데이터(Bound Data)의 경우 일부 관측치가 다음 줄로 이동되는 문제가 발생할 수 있습니다. 이 문제를 수정하는 do 파일이 이 핸드북에 제공됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a791d5",
   "metadata": {},
   "source": [
    "* 캐나다(CAN)의 최혜국(MFN) 적용 관세율 및 양허 관세율을 가져옵니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c387e44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pilsu\\AppData\\Local\\Temp\\ipykernel_27928\\3788704997.py:6: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"../Data/Chapter2/CAN08_{grp}_{file}_TL.txt\", delimiter='\\t')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Chapter2/CAN_NAG_DutyDetails.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/Chapter2/CAN_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDutyDetails\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTradeDetails\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTariffDetails\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBounds\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 36\u001b[0m     append_datasets(file)\n",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m, in \u001b[0;36mappend_datasets\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend_datasets\u001b[39m(file):\n\u001b[1;32m---> 26\u001b[0m     df_nag \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/Chapter2/CAN_NAG_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     df_ag \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/Chapter2/CAN_AG_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_nag, df_ag], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2020\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_stata_doc)\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath_or_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_stata\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2017\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2018\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m StataReader:\n\u001b[1;32m-> 2020\u001b[0m     reader \u001b[38;5;241m=\u001b[39m StataReader(\n\u001b[0;32m   2021\u001b[0m         filepath_or_buffer,\n\u001b[0;32m   2022\u001b[0m         convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[0;32m   2023\u001b[0m         convert_categoricals\u001b[38;5;241m=\u001b[39mconvert_categoricals,\n\u001b[0;32m   2024\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   2025\u001b[0m         convert_missing\u001b[38;5;241m=\u001b[39mconvert_missing,\n\u001b[0;32m   2026\u001b[0m         preserve_dtypes\u001b[38;5;241m=\u001b[39mpreserve_dtypes,\n\u001b[0;32m   2027\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   2028\u001b[0m         order_categoricals\u001b[38;5;241m=\u001b[39morder_categoricals,\n\u001b[0;32m   2029\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   2030\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2031\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   2032\u001b[0m     )\n\u001b[0;32m   2034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterator \u001b[38;5;129;01mor\u001b[39;00m chunksize:\n\u001b[0;32m   2035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1163\u001b[0m, in \u001b[0;36mStataReader.__init__\u001b[1;34m(self, path_or_buf, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, compression, storage_options)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lines_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_native_byteorder \u001b[38;5;241m=\u001b[39m _set_endianness(sys\u001b[38;5;241m.\u001b[39mbyteorder)\n\u001b[1;32m-> 1163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1164\u001b[0m     path_or_buf,\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1167\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1168\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   1169\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;66;03m# Copy to BytesIO, and ensure no encoding\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_or_buf \u001b[38;5;241m=\u001b[39m BytesIO(handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_header()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Chapter2/CAN_NAG_DutyDetails.dta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to import data from ../Data/ folder\n",
    "def import_data(grp, file):\n",
    "    df = pd.read_csv(f\"../Data/Chapter2/CAN08_{grp}_{file}_TL.txt\", delimiter='\\t')\n",
    "    df.sort_values(by='TL', inplace=True)\n",
    "    df.to_csv(f\"CAN_{grp}_{file}.csv\", index=False)\n",
    "\n",
    "def convert_to_string(df):\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "# Import MFN applied and bound tariff rates for CAN\n",
    "for grp in ['AG', 'NAG']:\n",
    "    for file in ['DutyDetails', 'TradeDetails', 'TariffDetails']:\n",
    "        import_data(grp, file)\n",
    "\n",
    "    # Convert all variables in string to allow append later and avoid issues\n",
    "    df_bounds = pd.read_csv(f\"../Data/Chapter2/CAN_{grp}_Concession_CO.txt\", delimiter='\\t')\n",
    "    df_bounds = convert_to_string(df_bounds)\n",
    "    df_bounds.to_csv(f\"CAN_{grp}_Bounds.csv\", index=False)\n",
    "\n",
    "# Append the agricultural and non-agricultural datasets\n",
    "def append_datasets(file):\n",
    "    df_nag = pd.read_stata(f\"../Data/Chapter2/CAN_NAG_{file}.dta\")\n",
    "    df_ag = pd.read_stata(f\"../Data/Chapter2/CAN_AG_{file}.dta\")\n",
    "    df = pd.concat([df_nag, df_ag], ignore_index=True)\n",
    "    \n",
    "    # Check for potential duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values(by='TL', inplace=True)\n",
    "    df.to_csv(f\"../Data/Chapter2/CAN_{file}.dta\", index=False)\n",
    "\n",
    "for file in ['DutyDetails', 'TradeDetails', 'TariffDetails', 'Bounds']:\n",
    "    append_datasets(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab57231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to import data from ../Data/ folder\n",
    "def import_data(grp, file):\n",
    "    df = pd.read_csv(f\"../Data/CAN08_{grp}_{file}_TL.txt\", delimiter='\\t')\n",
    "    df.sort_values(by='tl', inplace=True)\n",
    "    df.to_stata(f\"CAN_{grp}_{file}.dta\", write_index=False)\n",
    "\n",
    "def convert_to_string(df):\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "# Import MFN applied and bound tariff rates for CAN\n",
    "for grp in ['ag', 'nag']:\n",
    "    for file in ['DutyDetails', 'TradeDetails', 'TariffDetails']:\n",
    "        import_data(grp, file)\n",
    "\n",
    "    # Convert all variables in string to allow append later and avoid issues\n",
    "    df_bounds = pd.read_csv(f\"../Data/CAN_{grp}_Concession_CO.txt\", delimiter='\\t')\n",
    "    df_bounds = convert_to_string(df_bounds)\n",
    "    df_bounds.to_stata(f\"CAN_{grp}_Bounds.dta\", write_index=False)\n",
    "\n",
    "# Append the agricultural and non-agricultural datasets\n",
    "def append_datasets(file):\n",
    "    df_nag = pd.read_stata(f\"CAN_nag_{file}.dta\")\n",
    "    df_ag = pd.read_stata(f\"CAN_ag_{file}.dta\")\n",
    "    df = pd.concat([df_nag, df_ag], ignore_index=True)\n",
    "    \n",
    "    # Check for potential duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values(by='tl', inplace=True)\n",
    "    df.to_stata(f\"CAN_{file}.dta\", write_index=False)\n",
    "\n",
    "for file in ['DutyDetails', 'TradeDetails', 'TariffDetails', 'Bounds']:\n",
    "    append_datasets(file)\n",
    "\n",
    "# Correct database when data is shifted due to problem with original file\n",
    "def import_and_correct_shifted_data(grp):\n",
    "    df = pd.read_csv(f\"../Data/CAN_{grp}_Concession_CO.txt\", delimiter='\\t')\n",
    "    df['agr'] = grp\n",
    "    df.to_stata(f\"CAN_{grp}_Bounds.dta\", write_index=False)\n",
    "    \n",
    "for grp in ['ag', 'nag']:\n",
    "    import_and_correct_shifted_data(grp)\n",
    "\n",
    "# Append the agricultural and non-agricultural datasets for bounds\n",
    "df_ag_bounds = pd.read_stata(\"CAN_ag_Bounds.dta\")\n",
    "df_nag_bounds = pd.read_stata(\"CAN_nag_Bounds.dta\")\n",
    "df_bounds = pd.concat([df_ag_bounds, df_nag_bounds], ignore_index=True)\n",
    "df_bounds.drop_duplicates(inplace=True)\n",
    "\n",
    "# Perform necessary transformations and corrections\n",
    "df_bounds = df_bounds[df_bounds['basenomenclature'] != \"\"]\n",
    "df_bounds['lgth'] = df_bounds['basenomenclature'].str.len()\n",
    "df_bounds['id'] = range(1, len(df_bounds) + 1)\n",
    "\n",
    "# Save temporary file\n",
    "df_bounds.to_stata(\"Bndstemp.dta\", write_index=False)\n",
    "\n",
    "# Further steps to correct the shifted data and make adjustments\n",
    "# Rename variables, drop unnecessary lines, and clean the data\n",
    "def rename_and_clean_data(df):\n",
    "    df = df.rename(columns=lambda x: x.replace(\"boundduty\", \"bndd\")\n",
    "                                      .replace(\"odcduty\", \"od\")\n",
    "                                      .replace(\"bound\", \"bnd\")\n",
    "                                      .replace(\"description\", \"des\")\n",
    "                                      .replace(\"other\", \"ot\")\n",
    "                                      .replace(\"binding\", \"bi\")\n",
    "                                      .replace(\"nature\", \"nt\")\n",
    "                                      .replace(\"status\", \"st\")\n",
    "                                      .replace(\"safeguard\", \"safg\")\n",
    "                                      .replace(\"baseduty\", \"bd\")\n",
    "                                      .replace(\"implementation\", \"imp\")\n",
    "                                      .replace(\"present\", \"pr\")\n",
    "                                      .replace(\"text\", \"tx\")\n",
    "                                      .replace(\"instrument\", \"ins\")\n",
    "                                      .replace(\"information\", \"if\")\n",
    "                                      .replace(\"classification\", \"cls\")\n",
    "                                      .replace(\"special\", \"spe\")\n",
    "                                      .replace(\"product\", \"pd\")\n",
    "                                      .replace(\"earlierin\", \"ein\")\n",
    "                                      .replace(\"base\", \"bs\")\n",
    "                                      .replace(\"nomenclature\", \"nom\")\n",
    "                                      .replace(\"reporter\", \"rep\")\n",
    "                                      .replace(\"code\", \"cod\"))\n",
    "    df = df.rename(columns={'queryname': 'qr', 'year': 'yr', 'certified': 'cert', 'source': 'so'})\n",
    "    return df\n",
    "\n",
    "df_bounds = rename_and_clean_data(df_bounds)\n",
    "\n",
    "# Final adjustments and saving the cleaned data\n",
    "df_bounds.to_stata(\"ShiftedData.dta\", write_index=False)\n",
    "\n",
    "# Append shifted data with original data\n",
    "df_bndstemp = pd.read_stata(\"Bndstemp.dta\")\n",
    "df_shifted_data = pd.read_stata(\"ShiftedData.dta\")\n",
    "df_bndstemp = df_bndstemp[df_bndstemp['lgth'] == 22]\n",
    "df_combined = pd.concat([df_bndstemp, df_shifted_data], ignore_index=True)\n",
    "\n",
    "# Final data cleaning and saving\n",
    "df_combined.drop(columns=['productdescription'], inplace=True)\n",
    "df_combined['basenomenclature'] = df_combined['basenomenclature'].unique()[0]\n",
    "df_combined['reportercode'] = df_combined['reportercode'].unique()[0]\n",
    "df_combined['reporter'] = df_combined['reporter'].unique()[0]\n",
    "df_combined['year'] = df_combined['year'].unique()[0]\n",
    "\n",
    "df_combined['productclassification'] = df_combined.apply(\n",
    "    lambda row: \"HS - WTO Agricultural Products Definition\" if row['agr'] == \"ag\" and row['productclassification'] == \"\" else (\n",
    "        \"HS - WTO Non-agricultural Products Definition\" if row['agr'] == \"nag\" and row['productclassification'] == \"\" else row['productclassification']), axis=1\n",
    ")\n",
    "df_combined = df_combined[df_combined['tl'] != \"\"]\n",
    "df_combined['queryname'] = df_combined['queryname'].apply(lambda x: \"\" if x != \"\" else x)\n",
    "df_combined.sort_values(by='id', inplace=True)\n",
    "\n",
    "# Destring numerical variables\n",
    "numerical_vars = ['bounddutyav', 'odcdutyav', 'basedutyav', 'implementationfrom', 'implementationto']\n",
    "for var in numerical_vars:\n",
    "    df_combined[var] = pd.to_numeric(df_combined[var], errors='coerce')\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "df_combined.to_stata(\"CAN_Bounds.dta\", write_index=False)\n",
    "\n",
    "# Erase temporary files\n",
    "os.remove(\"Bndstemp.dta\")\n",
    "os.remove(\"ShiftedData.dta\")\n",
    "\n",
    "# Erase construction files\n",
    "for grp in ['ag', 'nag']:\n",
    "    for file in ['DutyDetails', 'TradeDetails', 'TariffDetails']:\n",
    "        os.remove(f\"CAN_{grp}_{file}.dta\")\n",
    "\n",
    "for file in [\"CAN_ag_Bounds.dta\", \"CAN_Nag_Bounds.dta\", \"CAN_TariffDetails.dta\"]:\n",
    "    os.remove(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
